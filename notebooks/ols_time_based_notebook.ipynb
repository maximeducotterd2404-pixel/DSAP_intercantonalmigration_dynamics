{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6e1de5",
   "metadata": {},
   "source": [
    "\n",
    "# OLS sklearn — Time‑based Validation (Migration Panel)\n",
    "\n",
    "This notebook implements a **Linear Regression (OLS)** using `sklearn` on your migration panel:\n",
    "- Rebuilds features (including interactions and canton dummies)\n",
    "- **Time-based train/test split** (80/20 by year)\n",
    "- Evaluates **MSE** and **R²** on the test period\n",
    "- Optional: **TimeSeriesSplit** cross-validation for robustness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3893589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 285 rows\n",
      "After initial cleaning: 260 rows\n",
      "Rows kept after numeric coercion: 260 (dropped 0)\n",
      "Split shapes -> X_train (208, 35) X_test (52, 35) y_train (208,) y_test (52,)\n",
      "\n",
      "=== Sklearn OLS (LinearRegression) ===\n",
      "MSE: 0.0650\n",
      "R^2: 0.3827\n",
      "\n",
      "First 5 predictions vs true:\n",
      "pred=-0.162 | true=-0.180\n",
      "pred=-0.020 | true=0.210\n",
      "pred=0.330 | true=0.370\n",
      "pred=-0.167 | true=0.090\n",
      "pred=-0.483 | true=-0.460\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Sklearn OLS baseline for migration_rate\n",
    "Pattern: split -> model -> fit -> predict -> evaluate\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#charge and clean data --> change the path with yours\n",
    "DATA_PATH = ROOT = Path(\"/Users/maximeducotterd/Desktop/DSAP_intercantonal_dynamics\")\n",
    "DATA_PATH = ROOT / \"data\" / \"databasecsv.csv\"\n",
    "df = pd.read_csv(DATA_PATH, sep=\";\")\n",
    "df.columns = df.columns.str.strip()\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "\n",
    "# Variables de base (comme dans essairegression.py)\n",
    "base_vars = [\n",
    "    \"log_rent_avg\",\n",
    "    \"log_avg_income\",\n",
    "    \"log_unemployment\",\n",
    "    \"log_schockexposure\",\n",
    "    \"CLUSTER1\",\n",
    "    \"CLUSTER2\",\n",
    "]\n",
    "\n",
    "# Interactions terms\n",
    "df[\"log_avg_income_x_log_rent_avg\"] = df[\"log_avg_income\"] * df[\"log_rent_avg\"]\n",
    "df[\"log_unemployment_rate_x_log_avg_income\"] = df[\"log_unemployment\"] * df[\"log_avg_income\"]\n",
    "df[\"log_schockexposure_x_CLUSTER1\"] = df[\"log_schockexposure\"] * df[\"CLUSTER1\"]\n",
    "df[\"log_schockexposure_x_CLUSTER2\"] = df[\"log_schockexposure\"] * df[\"CLUSTER2\"]\n",
    "\n",
    "interaction_vars = [\n",
    "    \"log_avg_income_x_log_rent_avg\",\n",
    "    \"log_unemployment_rate_x_log_avg_income\",\n",
    "    \"log_schockexposure_x_CLUSTER1\",\n",
    "    \"log_schockexposure_x_CLUSTER2\",\n",
    "]\n",
    "\n",
    "required_cols = [\"migration_rate\", \"canton\", \"year\"] + base_vars + interaction_vars\n",
    "df_model = df.dropna(subset=required_cols).copy()\n",
    "print(f\"After initial cleaning: {len(df_model)} rows\")\n",
    "\n",
    "# Dummies canton \n",
    "df_model = pd.get_dummies(df_model, columns=[\"canton\"], drop_first=True)\n",
    "\n",
    "# We have to ensure \"year\" is numeric\n",
    "df_model[\"year\"] = pd.to_numeric(df_model[\"year\"], errors=\"coerce\")\n",
    "\n",
    "# Finales feature\n",
    "feature_cols = base_vars + interaction_vars + [c for c in df_model.columns if c.startswith(\"canton_\")]\n",
    "\n",
    "# Conversion in numeric\n",
    "X_df = df_model[feature_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "y_ser = pd.to_numeric(df_model[\"migration_rate\"], errors=\"coerce\")\n",
    "\n",
    "# Drop invalids lines\n",
    "mask_valid = (~X_df.isna().any(axis=1)) & (~y_ser.isna()) & (~df_model[\"year\"].isna())\n",
    "before = len(df_model)\n",
    "X_df = X_df.loc[mask_valid]\n",
    "y_ser = y_ser.loc[mask_valid]\n",
    "df_model = df_model.loc[mask_valid].copy()\n",
    "after = len(df_model)\n",
    "\n",
    "print(f\"Rows kept after numeric coercion: {after} (dropped {before-after})\")\n",
    "\n",
    "# temporal train-test split based on years\n",
    "df_sorted = df_model.sort_values([\"year\"]).reset_index(drop=True)\n",
    "years = df_sorted[\"year\"].unique()\n",
    "cut = int(0.8 * len(years)) if len(years) > 1 else 1\n",
    "\n",
    "train_years = set(years[:cut])\n",
    "test_years = set(years[cut:]) if cut < len(years) else set()\n",
    "\n",
    "X_train = df_sorted.loc[df_sorted[\"year\"].isin(train_years), feature_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy()\n",
    "y_train = pd.to_numeric(df_sorted.loc[df_sorted[\"year\"].isin(train_years), \"migration_rate\"], errors=\"coerce\").to_numpy()\n",
    "X_test  = df_sorted.loc[df_sorted[\"year\"].isin(test_years),  feature_cols].apply(pd.to_numeric, errors=\"coerce\").to_numpy()\n",
    "y_test  = pd.to_numeric(df_sorted.loc[df_sorted[\"year\"].isin(test_years),  \"migration_rate\"], errors=\"coerce\").to_numpy()\n",
    "\n",
    "print(\"Split shapes ->\",\n",
    "      \"X_train\", X_train.shape, \"X_test\", X_test.shape,\n",
    "      \"y_train\", y_train.shape, \"y_test\", y_test.shape)\n",
    "\n",
    "# model creation\n",
    "model = LinearRegression()\n",
    "\n",
    "# training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n=== Sklearn OLS (LinearRegression) ===\")\n",
    "print(f\"MSE: {mse:.4f}\")\n",
    "print(f\"R^2: {r2:.4f}\")\n",
    "\n",
    "# Aperçu debug\n",
    "print(\"\\nFirst 5 predictions vs true:\")\n",
    "for yp, yt in list(zip(y_pred[:5], y_test[:5])):\n",
    "    print(f\"pred={yp:.3f} | true={yt:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77640458",
   "metadata": {},
   "source": [
    "## OLS Model – Quick Interpretation ##\n",
    "The OLS model gives an R² of 0.39 on the test years. This means the variables we use (rent, income, unemployment, shock exposure, clusters, canton dummies) explain about 40% of the variation in net migration across cantons. For real Swiss panel data, this is a decent result.\n",
    "The MSE is 0.064, which corresponds to an average prediction error of roughly 0.25 points of net migration. The first predictions also look close to the true values, so the model captures the general level and direction of migration, even if some observations are harder to predict.\n",
    "Overall, this OLS is a good baseline model. It shows that economic fundamentals contain real predictive signal, but a large part of migration is still driven by other factors (policy, quality of life, city attractiveness, demographics, etc.). This baseline will help compare future models like Ridge or Random Forest."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (capstone_env)",
   "language": "python",
   "name": "capstone_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
